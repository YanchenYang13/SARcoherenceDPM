{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example: load feature and label arrays\n",
    "X = np.load(\"path_to_feature_file.npy\")\n",
    "Y = np.load(\"path_to_label_file.npy\")\n",
    "\n",
    "# Reshape data into format (N, C, H, W)\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1], X.shape[2])\n",
    "Y = Y.reshape(Y.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Files\n",
    "Feature file (.npy): A NumPy array storing the input data.\n",
    "Shape: (N, H, W)\n",
    "\n",
    "N: number of samples\n",
    "\n",
    "H, W: spatial dimensions of each sample\n",
    "\n",
    "Label file (.npy): A NumPy array storing the target values.\n",
    "Shape: (N,) or (N, 1) depending on the task.\n",
    "\n",
    "Both files should be created beforehand (e.g., from remote sensing .tif data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_x, data_y, split=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_x: feature matrix (numpy array)\n",
    "            data_y: labels (numpy array)\n",
    "            split: 0 = training, 1 = validation/test\n",
    "        \"\"\"\n",
    "        self.split = split\n",
    "        self.x = data_x\n",
    "        self.y = data_y\n",
    "        self.x_train, self.x_test = self.x, self.x\n",
    "        self.y_train, self.y_test = self.y, self.y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.split == 0:  # training\n",
    "            x_item, y_item = self.x_train[index], self.y_train[index]\n",
    "        else:                # validation/test\n",
    "            x_item, y_item = self.x_test[index], self.y_test[index]\n",
    "\n",
    "        return torch.tensor(x_item), torch.tensor(y_item)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0] if self.split == 0 else self.x_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import einsum\n",
    "\n",
    "# --- Helper functions ---\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# --- Model components ---\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim), \n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim=-1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), (q, k, v))\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
    "            ]) for _ in range(depth)\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim,\n",
    "                 pool='cls', channels=1, dim_head=64, dropout=0., emb_dropout=0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width),\n",
    "            nn.Linear(patch_dim, dim)\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]\n",
    "        return self.mlp_head(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
    "\n",
    "train_dataset = MyDataset(x_train, y_train, split=0)\n",
    "val_dataset   = MyDataset(x_test,  y_test,  split=1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=128, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ViT(\n",
    "    image_size = 12,\n",
    "    patch_size = 6,\n",
    "    num_classes = 1,\n",
    "    dim = 64,\n",
    "    depth = 6,\n",
    "    heads = 6,\n",
    "    mlp_dim = 64,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "train_loss, val_loss = [], []\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.float().to(device), labels.float().to(device)\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss.append(running_loss / len(train_loader))\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.float().to(device), labels.float().to(device)\n",
    "            labels = labels.view(-1, 1)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    val_loss.append(running_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss[-1]:.6f}, Val Loss: {val_loss[-1]:.6f}\")\n",
    "\n",
    "# Plot loss curves\n",
    "plt.plot(train_loss, label=\"Train\")\n",
    "plt.plot(val_loss, label=\"Validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model, \"vit_model.pth\")\n",
    "\n",
    "# Example: predictions on test set\n",
    "predictions = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in val_loader:\n",
    "        inputs = inputs.float().to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "print(\"Predictions shape:\", predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. Function: Normalized Difference Calculation\n",
    "# ============================================================\n",
    "def calculate_difference(interferogram1, interferogram2, chunk_size=1024):\n",
    "    \"\"\"\n",
    "    Compute the normalized difference between two interferograms\n",
    "    with block-wise processing to reduce memory usage.\n",
    "    \n",
    "    Args:\n",
    "        interferogram1 (np.ndarray): First interferogram (2D array).\n",
    "        interferogram2 (np.ndarray): Second interferogram (2D array).\n",
    "        chunk_size (int): Block size for processing to avoid memory overflow.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Difference map (float32), with NaN for invalid pixels.\n",
    "    \"\"\"\n",
    "    if interferogram1.shape != interferogram2.shape:\n",
    "        raise ValueError(\"Both interferograms must have the same shape.\")\n",
    "    \n",
    "    rows, cols = interferogram1.shape\n",
    "    difference = np.zeros((rows, cols), dtype=np.float32)\n",
    "\n",
    "    chunk_rows = max(1, min(chunk_size, rows))\n",
    "    chunk_cols = max(1, min(chunk_size, cols))\n",
    "\n",
    "    for i in range(0, rows, chunk_rows):\n",
    "        for j in range(0, cols, chunk_cols):\n",
    "            end_i = min(i + chunk_rows, rows)\n",
    "            end_j = min(j + chunk_cols, cols)\n",
    "\n",
    "            if end_i <= i or end_j <= j:\n",
    "                continue\n",
    "\n",
    "            chunk1 = interferogram1[i:end_i, j:end_j]\n",
    "            chunk2 = interferogram2[i:end_i, j:end_j]\n",
    "\n",
    "            epsilon = 1e-8\n",
    "            denominator = chunk1 + chunk2 + epsilon\n",
    "            valid_mask = denominator != 0\n",
    "\n",
    "            diff_chunk = np.full_like(chunk1, np.nan, dtype=np.float32)\n",
    "            diff_chunk[valid_mask] = (chunk1[valid_mask] - chunk2[valid_mask]) / denominator[valid_mask]\n",
    "\n",
    "            difference[i:end_i, j:end_j] = diff_chunk\n",
    "\n",
    "    mask = np.isnan(interferogram1) | np.isnan(interferogram2) | (interferogram1 == 0) | (interferogram2 == 0)\n",
    "    difference[mask] = np.nan\n",
    "\n",
    "    return difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. Input Data Description\n",
    "# ============================================================\n",
    "\n",
    "# Input files:\n",
    "# - assumed co-disaster value (predicted by the LSTM model)\n",
    "# - geninue co-disaster value (observed data)\n",
    "\n",
    "# Both should be saved as `.npy` files with shape (H, W),\n",
    "# where each element represents the interferometric phase\n",
    "# at pixel (i, j).\n",
    "\n",
    "# Example file structure:\n",
    "# base_dir/\n",
    "#   ├── geninue.npy     (geninue co-disaster value)\n",
    "#   ├── predicted.npy (predicted co-disaster value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. Load Input Data\n",
    "# ============================================================\n",
    "\n",
    "base_dir = \"/your/path/to/\"   # <-- Replace with your path\n",
    "\n",
    "file1_path = os.path.join(base_dir, \"geninue.npy\")   # ground truth\n",
    "file2_path = os.path.join(base_dir, \"predicted.npy\")  # model prediction\n",
    "\n",
    "ifg_true = np.load(file1_path)\n",
    "ifg_pred = np.load(file2_path)\n",
    "\n",
    "print(f\"Loaded file: {file1_path}, shape: {ifg_true.shape}\")\n",
    "print(f\"Loaded file: {file2_path}, shape: {ifg_pred.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. Compute Normalized Difference Score\n",
    "# ============================================================\n",
    "\n",
    "phase_score = calculate_difference(ifg_true, ifg_pred, chunk_size=512)\n",
    "\n",
    "# Apply masking for NaN/zeros\n",
    "phase_score = np.where(np.isnan(ifg_true), np.nan,\n",
    "                      np.where(ifg_true == 0, 0, phase_score))\n",
    "phase_score = np.where(np.isnan(ifg_pred), np.nan,\n",
    "                      np.where(ifg_pred == 0, 0, phase_score))\n",
    "\n",
    "print(\"Score map computed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. Save Results\n",
    "# ============================================================\n",
    "\n",
    "output_filename = \"score.npy\"\n",
    "output_path = os.path.join(base_dir, output_filename)\n",
    "\n",
    "np.save(output_path, phase_score)\n",
    "print(f\"Result saved as {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7. Visualization Example\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(ifg_true, cmap=\"viridis\")\n",
    "plt.title(\"Geninue Co-Disaster Value\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(ifg_pred, cmap=\"viridis\")\n",
    "plt.title(\"Predicted Co-Disaster Value\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(phase_score, cmap=\"bwr\", vmin=-1, vmax=1)\n",
    "plt.title(\"Normalized Difference Score\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
